{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6d8ade-f874-4559-a7cb-86cb5ce83486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T14:27:02.535908Z",
     "iopub.status.busy": "2024-08-15T14:27:02.535042Z",
     "iopub.status.idle": "2024-08-15T14:27:10.372661Z",
     "shell.execute_reply": "2024-08-15T14:27:10.371866Z",
     "shell.execute_reply.started": "2024-08-15T14:27:02.535874Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55889e1f-75a1-4d5d-af17-8bf71f42cb62",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-15T14:36:47.986827Z",
     "iopub.status.busy": "2024-08-15T14:36:47.986097Z",
     "iopub.status.idle": "2024-08-15T14:36:48.001025Z",
     "shell.execute_reply": "2024-08-15T14:36:48.000243Z",
     "shell.execute_reply.started": "2024-08-15T14:36:47.986772Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MetricsCalculator(object):  \n",
    "    def __init__(self):  \n",
    "        self.TP = 0  \n",
    "        self.FP = 0  \n",
    "        self.FN = 0  \n",
    "        self.TN = 0\n",
    "        self.y_trues = []\n",
    "        self.y_pred_onehot = []\n",
    "        self.y_preds_proba = []\n",
    "  \n",
    "    def update(self, y_true, y_pred, y_pred_onehot, y_pred_proba):  \n",
    "        y_true = np.array(y_true).reshape(-1, 1)  \n",
    "        y_pred = np.array(y_pred).reshape(-1, 1)\n",
    "        y_pred_onehot = np.array(y_pred_onehot).reshape(-1, 2)\n",
    "        y_pred_proba = np.array(y_pred_proba).reshape(-1, 2)\n",
    "\n",
    "        self.y_trues.extend(y_true)\n",
    "        self.y_pred_onehot.extend(y_pred_onehot)\n",
    "        self.y_preds_proba.extend(y_pred_proba)  # Update the correct variable here\n",
    "  \n",
    "        # 假设 y_true 中 1 表示正类，0 表示负类  \n",
    "        self.TP += np.sum((y_true == 1) & (y_pred == 1)) \n",
    "        self.FN += np.sum((y_true == 1) & (y_pred == 0))\n",
    "        self.FP += np.sum((y_true == 0) & (y_pred == 1))\n",
    "        self.TN += np.sum((y_true == 0) & (y_pred == 0))\n",
    "\n",
    "    def calculate_brier_score(self):\n",
    "        y_true = np.array(self.y_pred_onehot)\n",
    "        y_pred_proba = np.array(self.y_preds_proba)  # Use the correct variable here\n",
    "\n",
    "        # 计算 BS\n",
    "        BS = np.mean((y_true - y_pred_proba) ** 2, axis=0)[0]\n",
    "\n",
    "        # 计算 BSS\n",
    "        y_mean = np.mean(y_true, axis=0)[0]\n",
    "        reference_bs = np.mean((y_true[:, 0] - y_mean) ** 2, axis=0)\n",
    "        BSS = 1 - BS / reference_bs if reference_bs != 0 else 0\n",
    "\n",
    "        return BS, BSS\n",
    "\n",
    "    def calculate_metrics(self):  \n",
    "        print(np.array(self.y_preds_proba).shape)\n",
    "        total = self.TP + self.FN + self.FP + self.TN  \n",
    "  \n",
    "        Accuracy = (self.TP + self.TN) / total if total > 0 else 0  \n",
    "        Precision = self.TP / (self.TP + self.FP) if (self.TP + self.FP) > 0 else 0  \n",
    "        Recall = self.TP / (self.TP + self.FN) if (self.TP + self.FN) > 0 else 0  \n",
    "        FAR = self.FP / (self.FP + self.TP) if (self.FP + self.TP) > 0 else 0  \n",
    "        TSS = Recall - (self.FP / (self.FP + self.TN)) if (self.FP + self.TN) > 0 else 0\n",
    "        HSS = (2 * (self.TP * self.TN - self.FP * self.FN)) / ((self.TP + self.FN) * (self.FN + self.TN) + (self.TP + self.FP) * (self.FP + self.TN) + 1e-5)  \n",
    "        \n",
    "        BS, BSS = self.calculate_brier_score()\n",
    "  \n",
    "        metrics = {  \n",
    "            'TP': self.TP,  \n",
    "            'FP': self.FP,  \n",
    "            'FN': self.FN,  \n",
    "            'TN': self.TN,  \n",
    "            'Accuracy': Accuracy,  \n",
    "            'Precision': Precision,  \n",
    "            'Recall': Recall,  \n",
    "            'FAR': FAR,  \n",
    "            'TSS': TSS,  \n",
    "            'HSS': HSS,\n",
    "            'Brier Score (BS)': BS,\n",
    "            'Brier Skill Score (BSS)': BSS\n",
    "        }  \n",
    "        return metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153490e9-cf18-41be-ab37-8c9c0802c7c2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-15T14:27:13.773927Z",
     "iopub.status.busy": "2024-08-15T14:27:13.772991Z",
     "iopub.status.idle": "2024-08-15T14:27:13.782738Z",
     "shell.execute_reply": "2024-08-15T14:27:13.781885Z",
     "shell.execute_reply.started": "2024-08-15T14:27:13.773892Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_preprocess(data_path, chunk_size=1000):\n",
    "    labels_list = []\n",
    "    images_list = []\n",
    "\n",
    "    # Process data in chunks to save memory\n",
    "    for chunk in pd.read_csv(data_path, header=None, usecols=[3] + list(range(4, 16388)), chunksize=chunk_size):\n",
    "        labels_chunk = chunk.iloc[:, 0].values\n",
    "        images_chunk = chunk.iloc[:, 1:].values.astype('float32').reshape(-1, 128, 128)\n",
    "        \n",
    "        # Convert labels to binary\n",
    "        label_mapping = {'N': 0, 'C': 0, 'M': 1, 'X': 1}\n",
    "        labels_chunk = np.vectorize(label_mapping.get)(labels_chunk).astype('float32').reshape(-1, 1)\n",
    "        \n",
    "        # Resize and preprocess images\n",
    "        images_resized = np.array([cv2.resize(img, (224, 224), interpolation=cv2.INTER_LINEAR) for img in images_chunk])\n",
    "        images_resized = np.stack([images_resized]*3, axis=-1)  # Convert to 3 channels\n",
    "        images_resized = images_resized.transpose([0, 3, 1, 2])  # Change to (num_samples, channels, height, width)\n",
    "        images_resized /= 4000.0  # Normalize\n",
    "\n",
    "        labels_list.append(labels_chunk)\n",
    "        images_list.append(images_resized)\n",
    "\n",
    "        # Clear memory\n",
    "        del chunk, labels_chunk, images_chunk, images_resized\n",
    "        gc.collect()\n",
    "\n",
    "    labels = np.vstack(labels_list)[39::40, ...].reshape((-1, ))\n",
    "    images = np.vstack(images_list).reshape((-1, 40, 3, 224, 224)).transpose([0, 2, 1, 3, 4])\n",
    "\n",
    "    # Clear memory\n",
    "    del labels_list, images_list\n",
    "    gc.collect()\n",
    "\n",
    "    return torch.tensor(images[:, :, -32::2, ...]), torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ebdc6c-4c06-4087-8e9f-9c7f141ef8bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T14:27:16.419603Z",
     "iopub.status.busy": "2024-08-15T14:27:16.418873Z",
     "iopub.status.idle": "2024-08-15T14:27:16.729922Z",
     "shell.execute_reply": "2024-08-15T14:27:16.729061Z",
     "shell.execute_reply.started": "2024-08-15T14:27:16.419571Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(40)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "device = torch.device('cuda:0')\n",
    "weight = torch.tensor([0.569, 4.120], dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f83088e-dc24-4542-ad6e-844e43a31737",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_val = 55\n",
    "\n",
    "for dataset_id in range(10):\n",
    "    best_TSS = -1\n",
    "    best_BSS = -100\n",
    "    Train_Loss = []\n",
    "    Val_Loss = []\n",
    "    train_data, train_label = data_preprocess(f'DATA/feature/group9_Data2_image/{dataset_id}Train.csv')\n",
    "    val_data, val_label = data_preprocess(f'DATA/feature/group9_Data2_image/Sift/{dataset_id}Val.csv')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    train_dataset = TensorDataset(train_data, train_label)\n",
    "    val_dataset = TensorDataset(val_data, val_label)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=True, pin_memory=True)\n",
    "    \n",
    "    model_weights = torchvision.models.video.MViT_V2_S_Weights.DEFAULT\n",
    "    model = torchvision.models.video.mvit_v2_s(weights=model_weights).to(device)\n",
    "    model.head[1] = torch.nn.Linear(768, 2).to(device)\n",
    "    \n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.15)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(opt, start_factor=0.001, end_factor=1.0, total_iters=15)\n",
    "\n",
    "    for i in range(30):\n",
    "        batch_id = 0\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for img, label in train_loader:\n",
    "            batch_id += 1\n",
    "\n",
    "            pred = model(img.to(device))\n",
    "            loss = F.cross_entropy(pred, label.to(device), weight=weight)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if batch_id % batch_val == 0:\n",
    "                print(f'Epoch: {i+1}')\n",
    "                print(f'Train_Loss: {total_loss / batch_val}')\n",
    "                Train_Loss.append(total_loss / batch_val)\n",
    "                total_loss = 0\n",
    "\n",
    "                TSS = []\n",
    "                val_batch_id = 0\n",
    "                calculator = MetricsCalculator()\n",
    "                model.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for img, label in val_loader:\n",
    "                        val_batch_id += 1\n",
    "                        pred = model(img.to(device))\n",
    "                        loss = F.cross_entropy(pred, label.to(device), weight=weight)\n",
    "                        total_loss += loss.item()\n",
    "                        pred_label = torch.argmax(pred, dim=-1)\n",
    "                        y_pred_proba = F.softmax(pred, dim=-1)\n",
    "                        calculator.update(y_true=label.detach().cpu().numpy(), y_pred=pred_label.detach().cpu().numpy(), y_pred_proba=y_pred_proba.detach().cpu().numpy())\n",
    "\n",
    "                val_loss_avg = total_loss / val_batch_id\n",
    "                print(f'Val_Loss: {val_loss_avg}')\n",
    "                Val_Loss.append(val_loss_avg)\n",
    "                total_loss = 0\n",
    "\n",
    "                metric = calculator.calculate_metrics()\n",
    "                model_folder = 'interval_32/model_BSS/MViT_Sift/'\n",
    "                if not os.path.exists(model_folder):\n",
    "                    os.makedirs(model_folder)\n",
    "                # if best_TSS < metric['TSS']:\n",
    "                #     best_TSS = metric['TSS']\n",
    "                #     torch.save(model.state_dict(), model_folder + f'MViT{dataset_id}.pt')\n",
    "                # print(metric)\n",
    "                # print('Mean TSS: {}   Best_TSS:{}\\n'.format(metric['TSS'], best_TSS))\n",
    "                if best_BSS < metric['Brier Skill Score (BSS)']:\n",
    "                    best_BSS = metric['Brier Skill Score (BSS)']\n",
    "                    torch.save(model.state_dict(), model_folder + f'MViT{dataset_id}.pt')\n",
    "                print(metric)\n",
    "                print('Mean BSS: {}   Best_BSS:{}\\n'.format(metric['TSS'], best_TSS))\n",
    "\n",
    "                # Clear CUDA cache and collect garbage\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    loss_folder = 'interval_32/Loss_BSS/MViT_Sift/'\n",
    "    if not os.path.exists(loss_folder):\n",
    "        os.makedirs(loss_folder)\n",
    "    np.save(loss_folder + f'Train_Loss_{dataset_id}.npy', np.array(Train_Loss))\n",
    "    np.save(loss_folder + f'Val_Loss_{dataset_id}.npy', np.array(Val_Loss))\n",
    "\n",
    "    # Clear CUDA cache and collect garbage after each dataset\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a6919c-f814-43b8-a585-6946fa463abd",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-15T14:36:55.506168Z",
     "iopub.status.busy": "2024-08-15T14:36:55.505418Z",
     "iopub.status.idle": "2024-08-15T14:42:51.864093Z",
     "shell.execute_reply": "2024-08-15T14:42:51.863287Z",
     "shell.execute_reply.started": "2024-08-15T14:36:55.506128Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dataset_id in range(0, 10):\n",
    "    test_data, test_label = data_preprocess(f'DATA/feature/group9_Data2_image/Sift/{dataset_id}Test.csv')\n",
    "    # test_data = test_data[39::40, ...]\n",
    "    # test_label = test_label[39::40, ...]\n",
    "    test_dataset = TensorDataset(test_data, test_label)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "    model = torchvision.models.video.mvit_v2_s().to(device)\n",
    "    model.head[1] = torch.nn.Linear(768, 2).to(device)\n",
    "    calculator = MetricsCalculator()\n",
    "    param = torch.load(f'interval_32/model/MViT_Sift/MViT{dataset_id}.pt')\n",
    "    model.load_state_dict(param)\n",
    "    model.eval()\n",
    "\n",
    "    TSS = []\n",
    "    with torch.no_grad():\n",
    "        for img, label in test_loader:\n",
    "            pred = model(img.to(device))\n",
    "            pred_label = torch.argmax(pred, axis=-1)\n",
    "            pred_onehot = F.one_hot(label, 2)\n",
    "            pred_proba = F.softmax(pred, dim=-1)\n",
    "            calculator.update(label, pred_label.detach().cpu().numpy(), pred_onehot.detach().cpu().numpy(), pred_proba.detach().cpu().numpy())\n",
    "    metric = calculator.calculate_metrics()\n",
    "    print(metric)\n",
    "\n",
    "    metric_folder = 'interval_32/Metrics_BSS/MViT_Sift/'\n",
    "    if not os.path.exists(metric_folder):\n",
    "        os.makedirs(metric_folder)\n",
    "    data_serializable = {k: int(v) if isinstance(v, np.integer) else v for k, v in metric.items()} \n",
    "    with open(metric_folder + f'dataset_{dataset_id}.json', 'w', encoding='utf-8') as f:  \n",
    "        json.dump(data_serializable, f, ensure_ascii=True, indent=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82d29e13-23dc-4534-b4aa-a630db0ff00f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T14:43:05.409643Z",
     "iopub.status.busy": "2024-08-15T14:43:05.408912Z",
     "iopub.status.idle": "2024-08-15T14:43:05.421136Z",
     "shell.execute_reply": "2024-08-15T14:43:05.420353Z",
     "shell.execute_reply.started": "2024-08-15T14:43:05.409609Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 19, 'FP': 13, 'FN': 1, 'TN': 78, 'Accuracy': 0.8738738738738738, 'Precision': 0.59375, 'Recall': 0.95, 'FAR': 0.40625, 'TSS': 0.8071428571428572, 'HSS': 0.6540516459170712, 'Brier Score (BS)': 0.09620883224360378, 'Brier Skill Score (BSS)': 0.3486873505090975}\n",
      "{'TP': 17, 'FP': 10, 'FN': 2, 'TN': 90, 'Accuracy': 0.8991596638655462, 'Precision': 0.6296296296296297, 'Recall': 0.8947368421052632, 'FAR': 0.37037037037037035, 'TSS': 0.7947368421052632, 'HSS': 0.6789568330059425, 'Brier Score (BS)': 0.07629941137148981, 'Brier Skill Score (BSS)': 0.43132843977280655}\n",
      "{'TP': 15, 'FP': 5, 'FN': 3, 'TN': 84, 'Accuracy': 0.9252336448598131, 'Precision': 0.75, 'Recall': 0.8333333333333334, 'FAR': 0.25, 'TSS': 0.7771535580524345, 'HSS': 0.744172143621721, 'Brier Score (BS)': 0.14276238084689005, 'Brier Skill Score (BSS)': -0.020278713056207653}\n",
      "{'TP': 18, 'FP': 5, 'FN': 4, 'TN': 77, 'Accuracy': 0.9134615384615384, 'Precision': 0.782608695652174, 'Recall': 0.8181818181818182, 'FAR': 0.21739130434782608, 'TSS': 0.7572062084257207, 'HSS': 0.7448200634001634, 'Brier Score (BS)': 0.062418375181648465, 'Brier Skill Score (BSS)': 0.6257665488000499}\n",
      "{'TP': 14, 'FP': 5, 'FN': 3, 'TN': 81, 'Accuracy': 0.9223300970873787, 'Precision': 0.7368421052631579, 'Recall': 0.8235294117647058, 'FAR': 0.2631578947368421, 'TSS': 0.7653898768809849, 'HSS': 0.7308948375868881, 'Brier Score (BS)': 0.051236326830468644, 'Brier Skill Score (BSS)': 0.6282036994908058}\n",
      "{'TP': 14, 'FP': 4, 'FN': 6, 'TN': 76, 'Accuracy': 0.9, 'Precision': 0.7777777777777778, 'Recall': 0.7, 'FAR': 0.2222222222222222, 'TSS': 0.6499999999999999, 'HSS': 0.6753246731320627, 'Brier Score (BS)': 0.08371962431760195, 'Brier Skill Score (BSS)': 0.4767523480149879}\n",
      "{'TP': 17, 'FP': 5, 'FN': 3, 'TN': 92, 'Accuracy': 0.9316239316239316, 'Precision': 0.7727272727272727, 'Recall': 0.85, 'FAR': 0.22727272727272727, 'TSS': 0.7984536082474226, 'HSS': 0.7679722340903018, 'Brier Score (BS)': 0.06593387803156214, 'Brier Skill Score (BSS)': 0.5347583214566729}\n",
      "{'TP': 20, 'FP': 10, 'FN': 1, 'TN': 81, 'Accuracy': 0.9017857142857143, 'Precision': 0.6666666666666666, 'Recall': 0.9523809523809523, 'FAR': 0.3333333333333333, 'TSS': 0.8424908424908424, 'HSS': 0.7232704386269757, 'Brier Score (BS)': 0.1021874357921811, 'Brier Skill Score (BSS)': 0.32923119069747786}\n",
      "{'TP': 14, 'FP': 3, 'FN': 2, 'TN': 83, 'Accuracy': 0.9509803921568627, 'Precision': 0.8235294117647058, 'Recall': 0.875, 'FAR': 0.17647058823529413, 'TSS': 0.8401162790697675, 'HSS': 0.8192771055305559, 'Brier Score (BS)': 0.05127974723858326, 'Brier Skill Score (BSS)': 0.6122714460245493}\n",
      "{'TP': 18, 'FP': 12, 'FN': 3, 'TN': 73, 'Accuracy': 0.8584905660377359, 'Precision': 0.6, 'Recall': 0.8571428571428571, 'FAR': 0.4, 'TSS': 0.7159663865546217, 'HSS': 0.6164978277460256, 'Brier Score (BS)': 0.10136980230511222, 'Brier Skill Score (BSS)': 0.3619097486273162}\n",
      "10\n",
      "Accuracy: 0.9076939422252395 0.02594839410699375\n",
      "Percision: 0.7133531559481384 0.07927722668101288\n",
      "Recall: 0.8554305214908929 0.06881513331893645\n",
      "FAR: 0.2866468440518615 0.07927722668101288\n",
      "TSS: 0.7748656458969915 0.055037550694810596\n",
      "HSS: 0.7155237802657709 0.05659412184985418\n",
      "BSS: 0.43286303803375564 0.18656508587074092\n"
     ]
    }
   ],
   "source": [
    "read_folder ='interval_32/Metrics_BSS/MViT_Sift/'\n",
    "read_file = sorted(os.listdir(read_folder))[:]\n",
    "TSS = []\n",
    "Accuracy = []\n",
    "Recall = []\n",
    "FAR = []\n",
    "Percision = []\n",
    "HSS = []\n",
    "BSS = []\n",
    "for r_file in read_file:\n",
    "    r_file = os.path.join(read_folder, r_file)\n",
    "    with open(r_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        print(data)\n",
    "        TSS.append(data['TSS'])\n",
    "        Accuracy.append(data['Accuracy'])\n",
    "        Percision.append(data['Precision'])\n",
    "        Recall.append(data['Recall'])\n",
    "        FAR.append(data['FAR'])\n",
    "        HSS.append(data['HSS'])\n",
    "        BSS.append(data['Brier Skill Score (BSS)'])\n",
    "print(len(Recall))\n",
    "print('Accuracy:', np.mean(Accuracy), np.std(Accuracy))\n",
    "print('Percision:', np.mean(Percision), np.std(Percision))\n",
    "print('Recall:', np.mean(Recall), np.std(Recall))\n",
    "print('FAR:', np.mean(FAR), np.std(FAR))\n",
    "print('TSS:', np.mean(TSS), np.std(TSS))\n",
    "print('HSS:', np.mean(HSS), np.std(HSS))\n",
    "print('BSS:', np.mean(BSS), np.std(BSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11714b65-5d1b-4d08-9dda-0314829af423",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-14T16:26:18.305670Z",
     "iopub.status.busy": "2024-08-14T16:26:18.305194Z",
     "iopub.status.idle": "2024-08-14T16:26:18.317396Z",
     "shell.execute_reply": "2024-08-14T16:26:18.316551Z",
     "shell.execute_reply.started": "2024-08-14T16:26:18.305633Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 19, 'FP': 13, 'FN': 1, 'TN': 78, 'Accuracy': 0.8738738738738738, 'Precision': 0.59375, 'Recall': 0.95, 'FAR': 0.40625, 'TSS': 0.8071428571428572, 'HSS': 0.6540516459170712}\n",
      "{'TP': 17, 'FP': 10, 'FN': 2, 'TN': 90, 'Accuracy': 0.8991596638655462, 'Precision': 0.6296296296296297, 'Recall': 0.8947368421052632, 'FAR': 0.37037037037037035, 'TSS': 0.7947368421052632, 'HSS': 0.6789568330059425}\n",
      "{'TP': 15, 'FP': 5, 'FN': 3, 'TN': 84, 'Accuracy': 0.9252336448598131, 'Precision': 0.75, 'Recall': 0.8333333333333334, 'FAR': 0.25, 'TSS': 0.7771535580524345, 'HSS': 0.744172143621721}\n",
      "{'TP': 18, 'FP': 5, 'FN': 4, 'TN': 77, 'Accuracy': 0.9134615384615384, 'Precision': 0.782608695652174, 'Recall': 0.8181818181818182, 'FAR': 0.21739130434782608, 'TSS': 0.7572062084257207, 'HSS': 0.7448200634001634}\n",
      "{'TP': 14, 'FP': 5, 'FN': 3, 'TN': 81, 'Accuracy': 0.9223300970873787, 'Precision': 0.7368421052631579, 'Recall': 0.8235294117647058, 'FAR': 0.2631578947368421, 'TSS': 0.7653898768809849, 'HSS': 0.7308948375868881}\n",
      "{'TP': 14, 'FP': 4, 'FN': 6, 'TN': 76, 'Accuracy': 0.9, 'Precision': 0.7777777777777778, 'Recall': 0.7, 'FAR': 0.2222222222222222, 'TSS': 0.6499999999999999, 'HSS': 0.6753246731320627}\n",
      "{'TP': 17, 'FP': 5, 'FN': 3, 'TN': 92, 'Accuracy': 0.9316239316239316, 'Precision': 0.7727272727272727, 'Recall': 0.85, 'FAR': 0.22727272727272727, 'TSS': 0.7984536082474226, 'HSS': 0.7679722340903018}\n",
      "{'TP': 20, 'FP': 10, 'FN': 1, 'TN': 81, 'Accuracy': 0.9017857142857143, 'Precision': 0.6666666666666666, 'Recall': 0.9523809523809523, 'FAR': 0.3333333333333333, 'TSS': 0.8424908424908424, 'HSS': 0.7232704386269757}\n",
      "{'TP': 14, 'FP': 3, 'FN': 2, 'TN': 83, 'Accuracy': 0.9509803921568627, 'Precision': 0.8235294117647058, 'Recall': 0.875, 'FAR': 0.17647058823529413, 'TSS': 0.8401162790697675, 'HSS': 0.8192771055305559}\n",
      "{'TP': 18, 'FP': 12, 'FN': 3, 'TN': 73, 'Accuracy': 0.8584905660377359, 'Precision': 0.6, 'Recall': 0.8571428571428571, 'FAR': 0.4, 'TSS': 0.7159663865546217, 'HSS': 0.6164978277460256}\n",
      "10\n",
      "Accuracy: 0.9076939422252395 0.02594839410699375\n",
      "Percision: 0.7133531559481384 0.07927722668101288\n",
      "Recall: 0.8554305214908929 0.06881513331893645\n",
      "FAR: 0.2866468440518615 0.07927722668101288\n",
      "TSS: 0.7748656458969915 0.055037550694810596\n",
      "HSS: 0.7155237802657709 0.05659412184985418\n"
     ]
    }
   ],
   "source": [
    "read_folder ='interval_32/Metrics/MViT_Sift1/'\n",
    "read_file = sorted(os.listdir(read_folder))[:]\n",
    "TSS = []\n",
    "Accuracy = []\n",
    "Recall = []\n",
    "FAR = []\n",
    "Percision = []\n",
    "HSS = []\n",
    "BSS = []\n",
    "for r_file in read_file:\n",
    "    r_file = os.path.join(read_folder, r_file)\n",
    "    with open(r_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        print(data)\n",
    "        TSS.append(data['TSS'])\n",
    "        Accuracy.append(data['Accuracy'])\n",
    "        Percision.append(data['Precision'])\n",
    "        Recall.append(data['Recall'])\n",
    "        FAR.append(data['FAR'])\n",
    "        HSS.append(data['HSS'])\n",
    "print(len(Recall))\n",
    "print('Accuracy:', np.mean(Accuracy), np.std(Accuracy))\n",
    "print('Percision:', np.mean(Percision), np.std(Percision))\n",
    "print('Recall:', np.mean(Recall), np.std(Recall))\n",
    "print('FAR:', np.mean(FAR), np.std(FAR))\n",
    "print('TSS:', np.mean(TSS), np.std(TSS))\n",
    "print('HSS:', np.mean(HSS), np.std(HSS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c2e0caa-d11a-4bf4-9e81-7b74597f8b08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T12:07:13.691990Z",
     "iopub.status.busy": "2024-08-06T12:07:13.691496Z",
     "iopub.status.idle": "2024-08-06T12:07:13.702960Z",
     "shell.execute_reply": "2024-08-06T12:07:13.702361Z",
     "shell.execute_reply.started": "2024-08-06T12:07:13.691947Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 19, 'FP': 13, 'FN': 1, 'TN': 78, 'Accuracy': 0.8738738738738738, 'Precision': 0.59375, 'Recall': 0.95, 'FAR': 0.14285714285714285, 'TSS': 0.8071428571428572, 'HSS': 0.6540516459170712}\n",
      "{'TP': 17, 'FP': 10, 'FN': 2, 'TN': 90, 'Accuracy': 0.8991596638655462, 'Precision': 0.6296296296296297, 'Recall': 0.8947368421052632, 'FAR': 0.1, 'TSS': 0.7947368421052632, 'HSS': 0.6789568330059425}\n",
      "{'TP': 15, 'FP': 5, 'FN': 3, 'TN': 84, 'Accuracy': 0.9252336448598131, 'Precision': 0.75, 'Recall': 0.8333333333333334, 'FAR': 0.056179775280898875, 'TSS': 0.7771535580524345, 'HSS': 0.744172143621721}\n",
      "{'TP': 18, 'FP': 5, 'FN': 4, 'TN': 77, 'Accuracy': 0.9134615384615384, 'Precision': 0.782608695652174, 'Recall': 0.8181818181818182, 'FAR': 0.06097560975609756, 'TSS': 0.7572062084257207, 'HSS': 0.7448200634001634}\n",
      "{'TP': 14, 'FP': 5, 'FN': 3, 'TN': 81, 'Accuracy': 0.9223300970873787, 'Precision': 0.7368421052631579, 'Recall': 0.8235294117647058, 'FAR': 0.05813953488372093, 'TSS': 0.7653898768809849, 'HSS': 0.7308948375868881}\n",
      "{'TP': 14, 'FP': 4, 'FN': 6, 'TN': 76, 'Accuracy': 0.9, 'Precision': 0.7777777777777778, 'Recall': 0.7, 'FAR': 0.05, 'TSS': 0.6499999999999999, 'HSS': 0.6753246731320627}\n",
      "{'TP': 17, 'FP': 5, 'FN': 3, 'TN': 92, 'Accuracy': 0.9316239316239316, 'Precision': 0.7727272727272727, 'Recall': 0.85, 'FAR': 0.05154639175257732, 'TSS': 0.7984536082474226, 'HSS': 0.7679722340903018}\n",
      "{'TP': 20, 'FP': 10, 'FN': 1, 'TN': 81, 'Accuracy': 0.9017857142857143, 'Precision': 0.6666666666666666, 'Recall': 0.9523809523809523, 'FAR': 0.10989010989010989, 'TSS': 0.8424908424908424, 'HSS': 0.7232704386269757}\n",
      "{'TP': 14, 'FP': 3, 'FN': 2, 'TN': 83, 'Accuracy': 0.9509803921568627, 'Precision': 0.8235294117647058, 'Recall': 0.875, 'FAR': 0.03488372093023256, 'TSS': 0.8401162790697675, 'HSS': 0.8192771055305559}\n",
      "{'TP': 18, 'FP': 12, 'FN': 3, 'TN': 73, 'Accuracy': 0.8584905660377359, 'Precision': 0.6, 'Recall': 0.8571428571428571, 'FAR': 0.1411764705882353, 'TSS': 0.7159663865546217, 'HSS': 0.6164978277460256}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 0.7748656458969915, 0.055037550694810596)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_folder = 'interval_32/Metrics/MViT_Sift/'\n",
    "read_file = sorted(os.listdir(read_folder))[:]\n",
    "TSS = []\n",
    "for r_file in read_file:\n",
    "    r_file = os.path.join(read_folder, r_file)\n",
    "    with open(r_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        print(data)\n",
    "        TSS.append(data['TSS'])\n",
    "len(TSS), np.mean(TSS), np.std(TSS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
